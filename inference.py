import os
os.environ["HF_HOME"] = "/root/autodl-tmp/hf_cache"
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

import torch
import os
from datasets import load_dataset
from transformers import DetrImageProcessor, DetrForObjectDetection
from PIL import Image, ImageDraw, ImageFont
from torchvision.ops import nms
from io import BytesIO
from torchvision.ops import batched_nms

# ================= é…ç½®åŒºåŸŸ =================
LOCAL_DATA_DIR = "/root/autodl-tmp/coco_full"
MODEL_PATH = "/root/detr/detr-finetuned-coco" 
#MODEL_PATH = "/root/detr/detr-resnet-50-coco-80class"
# ===========================================

print("ğŸš€ æ­£åœ¨åˆå§‹åŒ–ç¯å¢ƒ...")

try:
    print(f"æ­£åœ¨ä» {LOCAL_DATA_DIR} åŠ è½½æ•°æ®...")
    data_files = {"validation": os.path.join(LOCAL_DATA_DIR, "data/val-*.parquet")}
    dataset = load_dataset("parquet", data_files=data_files, split="validation[:5]")
    print(f"æ•°æ®åŠ è½½æˆåŠŸï¼å…± {len(dataset)} å¼ å›¾ç‰‡ã€‚")
except Exception as e:
    print(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
    dataset = load_dataset("detection-datasets/coco", split="validation[:5]", streaming=True)


print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {MODEL_PATH}")
processor = DetrImageProcessor.from_pretrained(MODEL_PATH)
model = DetrForObjectDetection.from_pretrained(MODEL_PATH)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)
model.eval()
print(f"æ¨¡å‹å°±ç»ªï¼è¿è¡Œè®¾å¤‡: {device}")


COCO_80_CLASSES = [
    "person", "bicycle", "car", "motorcycle", "airplane", "bus", "train", "truck", "boat", "traffic light",
    "fire hydrant", "stop sign", "parking meter", "bench", "bird", "cat", "dog", "horse", "sheep", "cow",
    "elephant", "bear", "zebra", "giraffe", "backpack", "umbrella", "handbag", "tie", "suitcase", "frisbee",
    "skis", "snowboard", "sports ball", "kite", "baseball bat", "baseball glove", "skateboard", "surfboard",
    "tennis racket", "bottle", "wine glass", "cup", "fork", "knife", "spoon", "bowl", "banana", "apple",
    "sandwich", "orange", "broccoli", "carrot", "hot dog", "pizza", "donut", "cake", "chair", "couch",
    "potted plant", "bed", "dining table", "toilet", "tv", "laptop", "mouse", "remote", "keyboard", "cell phone",
    "microwave", "oven", "toaster", "sink", "refrigerator", "book", "clock", "vase", "scissors", "teddy bear",
    "hair drier", "toothbrush"
]



def detect(pil_img):
    inputs = processor(images=pil_img, return_tensors="pt")
    inputs = {k: v.to(device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model(**inputs)

    target_sizes = torch.tensor([pil_img.size[::-1]]).to(device)
    results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]

    boxes = results["boxes"]
    scores = results["scores"]
    labels = results["labels"]

    if boxes.shape[0] == 0:
        return []

    # ä½¿ç”¨ batched_nms
    # ä½œç”¨ï¼šåªæœ‰å½“â€œç±»åˆ«ç›¸åŒâ€ä¸”â€œé‡å åº¦é«˜â€æ—¶æ‰æŠ‘åˆ¶ã€‚
    keep_indices = batched_nms(boxes, scores, labels, iou_threshold=0.3)
    
    filtered_boxes = boxes[keep_indices]
    filtered_scores = scores[keep_indices]
    filtered_labels = labels[keep_indices]

    detections = []
    for score, label, box in zip(filtered_scores, filtered_labels, filtered_boxes):
        score = score.item()
        label_id = label.item()
        
        if 0 <= label_id < len(COCO_80_CLASSES):
            label_name = COCO_80_CLASSES[label_id]
        else:
            label_name = f"Unknown-{label_id}"

        box = box.cpu().numpy()
        x_min, y_min, x_max, y_max = box
        
        detections.append({
            "bbox": [x_min, y_min, x_max, y_max],
            "label": label_name,
            "score": score,
            "label_id": label_id
        })
        
    return detections

print(f"\n{'='*20} å¼€å§‹é¢„æµ‹ {'='*20}")

for i, item in enumerate(dataset):
    image_data = item['image']
    image_id = item.get('image_id', f'demo_{i}')

    if isinstance(image_data, dict) and 'bytes' in image_data:
        try:
            image = Image.open(BytesIO(image_data['bytes'])).convert('RGB')
        except Exception as e:
            continue
    elif isinstance(image_data, Image.Image):
        image = image_data
    else:
        continue
    
    print(f"\nğŸ“¸ å¤„ç†å›¾ç‰‡ [{i+1}/5] ID: {image_id}")
    
    detections = detect(image)
    
    if len(detections) == 0:
        print("   (æœªæ£€æµ‹åˆ°é«˜ç½®ä¿¡åº¦ç‰©ä½“)")
    else:
        for dt in detections:
            b = dt['bbox']
            print(f"æ£€æµ‹åˆ°: {dt['label']:<15} | ç½®ä¿¡åº¦: {dt['score']:.2f}")
            print(f"   ID: {dt['label_id']:<15} | BBox åŸå§‹æ•°æ®: {b}")
            
    if i < 5:
        draw = ImageDraw.Draw(image)
        try:
            font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", 20)
        except:
            font = None 

        for dt in detections:
            x_min, y_min, x_max, y_max = dt['bbox']
            draw.rectangle([x_min, y_min, x_max, y_max], outline='red', width=3)
            
            text_content = f"{dt['label']} {dt['score']:.2f}"
            if font:
                text_bbox = draw.textbbox((x_min, y_min), text_content, font=font)
            else:
                text_bbox = draw.textbbox((x_min, y_min), text_content)
            
            draw.rectangle([text_bbox[0], text_bbox[1], text_bbox[2], text_bbox[3]], fill='red')
            draw.text((x_min, y_min), text_content, fill='white', font=font)
        
        save_name = f"result_preview_{i}.jpg" 
        image.save(save_name)
        print(f"ç»“æœå·²ä¿å­˜ä¸º {save_name}")

print(f"\n{'='*20} æ¼”ç¤ºç»“æŸ {'='*20}")