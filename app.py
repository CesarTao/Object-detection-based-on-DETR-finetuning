import os
import torch
from flask import Flask, request, jsonify, render_template
from PIL import Image
from transformers import DetrImageProcessor, DetrForObjectDetection
from torchvision.ops import box_iou

app = Flask(__name__)

# ================= é…ç½®åŒºåŸŸ =================
# è¯·ç¡®ä¿è¿™é‡Œæ˜¯æ‚¨çš„æ­£ç¡®è·¯å¾„
MODEL_PATH = "/root/detr/detr-finetuned-coco-ver2"
# MODEL_PATH = "facebook/detr-resnet-50" # å¤‡ç”¨

COCO_CLASSES = [
    "person", "bicycle", "car", "motorcycle", "airplane", "bus", "train", "truck", "boat", "traffic light",
    "fire hydrant", "stop sign", "parking meter", "bench", "bird", "cat", "dog", "horse", "sheep", "cow",
    "elephant", "bear", "zebra", "giraffe", "backpack", "umbrella", "handbag", "tie", "suitcase", "frisbee",
    "skis", "snowboard", "sports ball", "kite", "baseball bat", "baseball glove", "skateboard", "surfboard",
    "tennis racket", "bottle", "wine glass", "cup", "fork", "knife", "spoon", "bowl", "banana", "apple",
    "sandwich", "orange", "broccoli", "carrot", "hot dog", "pizza", "donut", "cake", "chair", "couch",
    "potted plant", "bed", "dining table", "toilet", "tv", "laptop", "mouse", "remote", "keyboard", "cell phone",
    "microwave", "oven", "toaster", "sink", "refrigerator", "book", "clock", "vase", "scissors", "teddy bear",
    "hair drier", "toothbrush"
]

# ================= æ¨¡å‹åŠ è½½ =================
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Loading model from: {MODEL_PATH} (Device: {device})...")

try:
    processor = DetrImageProcessor.from_pretrained(MODEL_PATH)
    model = DetrForObjectDetection.from_pretrained(MODEL_PATH)
    model.to(device)
    model.eval()
    print("âœ… åç«¯æœåŠ¡å¯åŠ¨æˆåŠŸï¼")
except Exception as e:
    print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    exit() # å¼ºåˆ¶é€€å‡ºé˜²æ­¢è¯¯å¯¼

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/predict', methods=['POST'])
def predict():
    if 'image' not in request.files:
        return jsonify({"error": "No image uploaded"}), 400
    
    file = request.files['image']
    threshold = float(request.form.get('threshold', 0.5))
    gt_str = request.form.get('gt_boxes', '').strip()

    try:
        image = Image.open(file.stream).convert("RGB")
    except:
        return jsonify({"error": "Invalid image file"}), 400

    # 1. æ¨ç†
    inputs = processor(images=image, return_tensors="pt").to(device)
    with torch.no_grad():
        outputs = model(**inputs)

    # 2. åå¤„ç†
    target_sizes = torch.tensor([image.size[::-1]]).to(device)
    results = processor.post_process_object_detection(
        outputs, target_sizes=target_sizes, threshold=threshold
    )[0]

    # 3. å‡†å¤‡æ•°æ®
    predictions = []
    pred_boxes_tensor = []
    
    # å…ˆæ”¶é›†æ‰€æœ‰é¢„æµ‹æ¡†ï¼Œç”¨äºåç»­æ‰¹é‡è®¡ç®— IoU
    for box in results["boxes"]:
        pred_boxes_tensor.append(box.tolist())
    
    # 4. å¤„ç†çœŸå®æ¡† (GT) å¹¶è®¡ç®— IoU
    has_gt = False
    per_box_ious = [None] * len(pred_boxes_tensor) # é»˜è®¤å…¨æ˜¯ None
    mean_iou = "--"
    max_iou = "--"

    if gt_str and len(pred_boxes_tensor) > 0:
        try:
            gt_boxes = []
            for line in gt_str.split('\n'):
                # å…¼å®¹ä¸­æ–‡é€—å·
                line = line.replace('ï¼Œ', ',').strip()
                if not line: continue
                coords = [float(x) for x in line.split(',')]
                if len(coords) == 4:
                    gt_boxes.append(coords)
            
            if gt_boxes:
                has_gt = True
                gt_tensor = torch.tensor(gt_boxes).to(device)
                pred_tensor = torch.tensor(pred_boxes_tensor).to(device)
                
                # è®¡ç®—çŸ©é˜µ: [é¢„æµ‹æ¡†æ•°é‡, çœŸå®æ¡†æ•°é‡]
                iou_matrix = box_iou(pred_tensor, gt_tensor)
                
                # ä¸ºæ¯ä¸ªé¢„æµ‹æ¡†æ‰¾åˆ°åŒ¹é…åº¦æœ€é«˜çš„çœŸå®æ¡†çš„ IoU å€¼
                # max_vals: æ¯ä¸ªé¢„æµ‹æ¡†å¯¹åº”çš„æœ€å¤§ IoU
                max_vals, _ = iou_matrix.max(dim=1)
                
                # å­˜å…¥åˆ—è¡¨ä¾›å‰ç«¯è¡¨æ ¼ä½¿ç”¨
                per_box_ious = max_vals.tolist()
                
                # è®¡ç®—å…¨å±€æŒ‡æ ‡
                mean_iou = f"{max_vals.mean().item():.4f}"
                max_iou = f"{max_vals.max().item():.4f}"
                
        except Exception as e:
            print(f"GT Parse Error: {e}")

    # 5. ç»„è£…æœ€ç»ˆè¿”å›æ•°æ®
    for i, (score, label, box) in enumerate(zip(results["scores"], results["labels"], results["boxes"])):
        box_cpu = box.tolist()
        label_idx = label.item()
        label_name = COCO_CLASSES[label_idx] if label_idx < len(COCO_CLASSES) else str(label_idx)
        
        # è·å–è¯¥æ¡†çš„ IoU (å¦‚æœæœ‰)
        box_iou_val = per_box_ious[i] if has_gt else -1

        predictions.append({
            "label": label_name,
            "score": float(score),
            "box": box_cpu,
            "iou": box_iou_val # æ–°å¢å­—æ®µï¼šå•æ¡† IoU
        })

    return jsonify({
        "predictions": predictions,
        "iou": {
            "mean_iou": mean_iou,
            "max_iou": max_iou
        }
    })

if __name__ == '__main__':
    print("-" * 50)
    print("âœ… åç«¯æœåŠ¡å¯åŠ¨æˆåŠŸï¼")
    #print(f"ğŸ‘‰ è¯·åœ¨æµè§ˆå™¨è¾“å…¥: http://127.0.0.1:5000")
    print("-" * 50)
    app.run(host='0.0.0.0', port=6006, debug=True)