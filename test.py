import os
# 1. å¼ºåˆ¶ä½¿ç”¨å›½å†…é•œåƒ
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
# 2. (å¯é€‰) å¼ºåˆ¶æŒ‡å®šç¼“å­˜åˆ°æ•°æ®ç›˜ï¼Œé˜²æ­¢ç³»ç»Ÿç›˜çˆ†æ»¡
os.environ["HF_HOME"] = "/root/autodl-tmp/hf_cache"


import os
import torch
from datasets import load_dataset
from transformers import DetrImageProcessor, DetrForObjectDetection, TrainingArguments, Trainer
from PIL import Image, ImageDraw
import numpy as np
from io import BytesIO

# ================= 1. åŸºç¡€é…ç½® =================
os.environ["HF_HOME"] = "/root/autodl-tmp/hf_cache"
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
LOCAL_DATA_DIR = "/root/autodl-tmp/coco_full"
CHECKPOINT = "facebook/detr-resnet-50"
OUTPUT_DIR = "./detr-final-test"

# COCO 80 ç±» (0-79)
COCO_CLASSES = [
    "person", "bicycle", "car", "motorcycle", "airplane", "bus", "train", "truck", "boat", "traffic light",
    "fire hydrant", "stop sign", "parking meter", "bench", "bird", "cat", "dog", "horse", "sheep", "cow",
    "elephant", "bear", "zebra", "giraffe", "backpack", "umbrella", "handbag", "tie", "suitcase", "frisbee",
    "skis", "snowboard", "sports ball", "kite", "baseball bat", "baseball glove", "skateboard", "surfboard",
    "tennis racket", "bottle", "wine glass", "cup", "fork", "knife", "spoon", "bowl", "banana", "apple",
    "sandwich", "orange", "broccoli", "carrot", "hot dog", "pizza", "donut", "cake", "chair", "couch",
    "potted plant", "bed", "dining table", "toilet", "tv", "laptop", "mouse", "remote", "keyboard", "cell phone",
    "microwave", "oven", "toaster", "sink", "refrigerator", "book", "clock", "vase", "scissors", "teddy bear",
    "hair drier", "toothbrush"
]
id2label = {i: label for i, label in enumerate(COCO_CLASSES)}
label2id = {label: i for i, label in id2label.items()}

# ================= 2. æ•°æ®å‡†å¤‡ =================
print("ğŸš€ åŠ è½½æ•°æ®...")
data_files = {"train": os.path.join(LOCAL_DATA_DIR, "data/train-*.parquet")}
# âš ï¸ åªå– 10 å¼ å›¾è¿‡æ‹Ÿåˆ
full_dataset = load_dataset("parquet", data_files=data_files, split="train[:10]")
print(f"ğŸ§ª Final Test: ä½¿ç”¨ {len(full_dataset)} å¼ å›¾ç‰‡")

image_processor = DetrImageProcessor.from_pretrained(CHECKPOINT)

def train_transforms(batch):
    pixel_values = []
    labels = []
    
    for i in range(len(batch["image"])):
        img_data = batch["image"][i]
        image = Image.open(BytesIO(img_data['bytes'])).convert("RGB") if isinstance(img_data, dict) else img_data.convert("RGB")
        
        target_anns = []
        objects = batch["objects"][i]
        
        if len(objects['bbox']) > 0:
            for box, cat_id in zip(objects['bbox'], objects['category']):
                # 1. åæ ‡å¤„ç†: [xmin, ymin, xmax, ymax]
                x_min, y_min, x_max, y_max = float(box[0]), float(box[1]), float(box[2]), float(box[3])
                w = x_max - x_min
                h = y_max - y_min
                
                if w <= 1 or h <= 1: continue
                
                # 2. ID å¤„ç†: ç›´æ¥é€ä¼  (å› ä¸ºæ•°æ®å·²ç»æ˜¯ 0-79 äº†)
                # ä½ çš„ "ID 0" å¯¹åº” "person"ï¼Œä¸éœ€è¦æ˜ å°„
                cid = int(cat_id)
                if cid >= 80: 
                    # é˜²å¾¡æ€§ç¼–ç¨‹ï¼šä¸‡ä¸€æœ‰è„æ•°æ®
                    cid = cid % 80
                
                target_anns.append({
                    "image_id": batch["image_id"][i],
                    "category_id": cid, 
                    "isCrowd": 0,
                    "area": w * h,
                    "bbox": [x_min, y_min, w, h] # xywh
                })
        
        # 3. å­—å…¸åŒ…è£…
        formatted_annotations = {'image_id': batch["image_id"][i], 'annotations': target_anns}
        encoding = image_processor(images=image, annotations=formatted_annotations, return_tensors="pt")
        
        pixel_values.append(encoding["pixel_values"].squeeze())
        labels.append(encoding["labels"][0])
        
    return {"pixel_values": pixel_values, "labels": labels}

def collate_fn(batch):
    pixel_values = [item["pixel_values"] for item in batch]
    encoding = image_processor.pad(pixel_values, return_tensors="pt")
    labels = [item["labels"] for item in batch]
    return {"pixel_values": encoding["pixel_values"], "pixel_mask": encoding["pixel_mask"], "labels": labels}

train_dataset = full_dataset.with_transform(train_transforms)

# ================= 3. è®­ç»ƒé…ç½® =================
model = DetrForObjectDetection.from_pretrained(
    CHECKPOINT,
    id2label=id2label,
    label2id=label2id,
    ignore_mismatched_sizes=True
)

training_args = TrainingArguments(
    output_dir=OUTPUT_DIR,
    per_device_train_batch_size=4,
    # ğŸ”¥ ç­–ç•¥ï¼šå¤§ç«çŒ›ç‚’
    num_train_epochs=300,          
    learning_rate=1e-4,           
    weight_decay=0.0,             
    logging_steps=10,
    save_strategy="no",
    fp16=torch.cuda.is_available(),
    dataloader_num_workers=0,
    remove_unused_columns=False
)

trainer = Trainer(
    model=model,
    args=training_args,
    data_collator=collate_fn,
    train_dataset=train_dataset,
    tokenizer=image_processor,
)

# ================= 4. è¿è¡Œ =================
print("\nğŸ”¥ å¼€å§‹æœ€ç»ˆè®­ç»ƒ...")
trainer.train()

# ================= 5. éªŒè¯ (æ˜¾å¾®é•œæ¨¡å¼) =================
print(f"\n{'='*20} æœ€ç»ˆéªŒè¯ {'='*20}")
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
model.eval()

# å–ç¬¬ä¸€å¼ å›¾
sample = full_dataset[0]
image = Image.open(BytesIO(sample['image']['bytes'])).convert("RGB")
inputs = image_processor(images=image, return_tensors="pt").to(device)

with torch.no_grad():
    outputs = model(**inputs)

target_sizes = torch.tensor([image.size[::-1]]).to(device)

# ğŸš¨ é˜ˆå€¼è®¾ä¸º 0.0ï¼ŒæŸ¥çœ‹æ‰€æœ‰å¯èƒ½çš„é¢„æµ‹
results = image_processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.0)[0]
boxes, scores, labels = results["boxes"], results["scores"], results["labels"]

# æŒ‰ç…§åˆ†æ•°æ’åºï¼Œåªçœ‹å‰ 10 ä¸ª
if len(scores) > 0:
    topk = min(10, len(scores))
    indices = torch.topk(scores, topk).indices
    boxes = boxes[indices]
    scores = scores[indices]
    labels = labels[indices]

draw = ImageDraw.Draw(image)
print("ğŸ“¸ é¢„æµ‹ Top 10 (æ— é˜ˆå€¼):")

found_valid = False
for score, label, box in zip(scores, labels, boxes):
    label_str = COCO_CLASSES[label.item()]
    box = box.cpu().numpy()
    
    # æ‰“å° log
    print(f"  ğŸ‘‰ {label_str} | Score: {score:.4f} | Box: {box.astype(int)}")
    
    # åªè¦åˆ†æ•° > 0.1 å°±ç”»æ¡†
    if score > 0.1:
        found_valid = True
        draw.rectangle(box, outline='red', width=3)
        draw.text((box[0], box[1]), f"{label_str} {score:.2f}", fill='red')

if not found_valid:
    print("\nâš ï¸ å‰ 10 ä¸ªç»“æœåˆ†æ•°éƒ½å¾ˆä½ (<0.1)ã€‚æ¨¡å‹å¯èƒ½è¿˜åœ¨çº ç»“ï¼Œæˆ–è€…éœ€è¦æ›´ä¹…è®­ç»ƒã€‚")
else:
    print("\nâœ… çœ‹åˆ°é«˜åˆ†ç»“æœäº†ï¼")

image.save("final_success.jpg")
print("ğŸ–¼ï¸ ç»“æœå·²ä¿å­˜ä¸º final_success.jpg")